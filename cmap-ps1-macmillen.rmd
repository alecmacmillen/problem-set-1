---
title: "CMAP PS1"
author: "Alec MacMillen"
date: "10/22/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())

library(tidyverse)
library(haven)
library(broom)
library(cluster)
library(fpc)
library(factoextra)
library(ggdendro)
library(dendextend)
library(mixtools)
library(plotGMM)
library(skimr)
library(seriation)
library(clustertend)
library(clValid)

setwd("C:/Users/Alec/Documents/Academics/Second Year/Fall Quarter/MACS 40500 - Computational Methods for American Politics/Problem Sets/problem-set-1")
```

### Question 1 - Data Loading

Load the state legislative professionalism data.

```{r}
load("State Leg Prof Data & Codebook/legprof-components.v1.0.RData")
```

### Question 2 - Data Munging

Munge the data:
1. Select only continuous features,
2. Restrict data to 2009-10 legislative session,
3. Omit missing values,
4. Standardize input features,
5. Other steps necessary to make the data in workable form.

```{r}
legprof <- x %>% 
  select(state:expend) %>% 
  filter(sessid == "2009/10", complete.cases(.))

rownames(legprof) <- legprof$state

legprof_numeric <- legprof %>% 
  select(-c(state, sessid))

legprof_scale <- legprof_numeric %>%
  scale()
```

### Question 3 - Diagnosing Clusterability

```{r}
# Hopkins statistic
h_stat <- clustertend::hopkins(legprof_numeric, n = nrow(legprof)-1)
h_stat

# VAT ODI plot
# Create distance matrix
lpdist <- legprof_scale %>% dist()
seriation::dissplot(lpdist)
```

The Hopkins statistic is `r round(hstat, digits = 3)`, which is far from the $H = 0.5$ threshold, suggesting that the data is not *highly* clusterable, but is probably not generated by a completely random process - more likely a uniform one. This is not entirely unexpected given that we're attempting to cluster only 49 observations. The VAT ODI plot corroborates this: while there are not several well-formed black blocks representing clusters, the plot is more ordered than one that would result from a truly random dataset. This suggests that a cluster analysis could yield some useful and interesting results.

### Question 4 - Hierarchical clustering algorithm

```{r}
hc_complete <- lpdist %>% hclust(method = "complete") %>% as.dendrogram

ggdendrogram(hc_complete, rotate = TRUE, theme_dendro = FALSE, title = "Hierarchical clustering, complete linkage") +
  ggtitle("Hierarchical clustering, complete linkage (horizontal)")

hc_complete %>% 
  plot() %>% 
  title(main = "Hierarchical clustering, complete linkage", line = 1)
abline(h = 4, lty = 2)

```

An agglomerative hierarchical clustering algorithm using complete linkage appears to first cluster between what could be called a "highly professional" set of legislatures (CA, MA, NY, PA, OH, IL, MI) and all other remaining legislatures.

```{r}
legprof %>% 
  mutate(prof_check = ifelse(state %in% c("California", "Massachusetts", "New York",
                                          "Pennsylvania", "Ohio", "Illinois", "Michigan"), 1, 0)) %>% 
  group_by(prof_check) %>% 
  summarize(med_sal = median(salary_real),
            med_exp = median(expend))
```

A cursory comparison of these two clustered groups reveal that the smaller cluster of highly professional legislatures have a much higher median salary and median expenditures per legislator, as we might expect. The dendrogram appears to indicate that a large cluster split occurs when moving from 4 to 5 clusters, so let's examine why that is.

```{r}
cuts <- dendextend::cutree(hc_complete, k = c(4,5))

### Or, a simple matrix of assignments by iteration
table(`4 Clusters` = cuts[,1], 
      `5 Clusters` = cuts[,2])
```

Fully 30 states move from cluster 1 to cluster 2 when 5 clusters are used instead of 4.

```{r}
hclust_5 <- tibble(state = rownames(legprof), clust5 = cuts[,2])
legprof %>% 
  left_join(hclust_5, by = "state") %>% 
  group_by(clust5) %>% 
  summarize(med_sal = median(salary_real),
            med_exp = median(expend),
            med_tslength = median(t_slength),
            med_slength = median(slength))
```

When 5, rather than 4, clusters are used in hierarchical agglomerative clustering, a group of 30 states is split from cluster 1 into cluster 2 that appears to have a higher median salary and shorter session length than the states remaining in cluster 1.

### Question 5 - K-means

```{r}
set.seed(678)
kmeans_2 <- kmeans(legprof_scale, centers = 2, nstart = 15)
str(kmeans_2)

kmeans_2_df <- tibble(state = rownames(legprof), k2 = kmeans_2$cluster)
kmeans_2_df %>% filter(k2 == 1) %>% select(state)
legprof %>% 
  left_join(kmeans_2_df, by = "state") %>% 
  group_by(k2) %>% 
  summarize(med_sal = median(salary_real),
            med_exp = median(expend))

legprof %>% 
  left_join(kmeans_2_df, by = "state") %>% 
  mutate(k2 = as.factor(k2)) %>% 
  ggplot(aes(salary_real, fill = k2)) +
  geom_histogram(binwidth = 10) +
  labs(x = "Salary", y = "Count of states") +
  theme_bw() 

```

The k-means clustering algorithm appears to perform a similar clustering to the hierarchical algorithm - a small group of "highly professional" legislatures with much higher median salary and expenditures per legislature (in this case, California, Massachusetts, Michigan, New York, Ohio and Pennsylvania - the same group of states as before but without Illinois) are separated from the rest of the states into their own cluster immediately. However, a quick histogram of states by salary with cluster colors applied shows that we may have misclassified a state into the second, "less professional" cluster when its salary might suggest that it should be in the "more professional" cluster. This is one indication that 2 clusters might not be enough to adequately capture all the variation in the dataset.


### Question 6 - Gaussian mixture model

Because our experience with previous model fits suggests that clusters are strongly distinguished by a state legislature's real salary, let's fit a Gaussian mixture model 

```{r}
# Let's cluster specifically on real salary
gmm1 <- mixtools::normalmixEM(legprof[,5], k = 2)
str(gmm1)

ggplot(data.frame(x = gmm1$x)) +
  geom_histogram(aes(x, ..density..), fill = "darkgray") +
  stat_function(geom = "line", fun = plot_mix_comps,
                args = list(gmm1$mu[1], gmm1$sigma[1], lam = gmm1$lambda[1]),
                colour = "darkgreen") +
  stat_function(geom = "line", fun = plot_mix_comps,
                args = list(gmm1$mu[2], gmm1$sigma[2], lam = gmm1$lambda[2]),
                colour = "darkblue") +
  ylab("Density") + 
  theme_bw() + 
  ggtitle("Gaussian mixture model, k = 2, real salary")
```

Fitting a Gaussian mixture model with 2 clusters on real salary results in one fairly tight distribution and another that is much more spread - it could be possible that the high outlier (California) is skewing the distribution, or it could be the case that a bimodal distribution is not the best approximation of how the data are generated.

One important note is that the real salary for California legislators dwarfs the salary of legislators in every other state - let's try dropping California and seeing whether that impacts the model.

```{r}
# Now let's try dropping California and repeating the process
legprof_noca <- legprof[-c(5),]
gmm2 <- mixtools::normalmixEM(legprof_noca[,5], k = 2)
str(gmm2)

ggplot(data.frame(x = gmm2$x)) +
  geom_histogram(aes(x, ..density..), fill = "darkgray") +
  stat_function(geom = "line", fun = plot_mix_comps,
                args = list(gmm2$mu[1], gmm2$sigma[1], lam = gmm2$lambda[1]),
                colour = "darkgreen") +
  stat_function(geom = "line", fun = plot_mix_comps,
                args = list(gmm2$mu[2], gmm2$sigma[2], lam = gmm2$lambda[2]),
                colour = "darkblue") +
  ylab("Density") + 
  theme_bw() + 
  ggtitle("Gaussian mixture model, k = 2, real salary, without CA")
```

Doesn't seem to make that much of a difference - we still have one fairly tight distribution and one fairly spread.

### Question 7: Comparing output


### Question 8: Validation

```{r}
legprof_mat <- as.matrix(legprof[,3:6])
internal_all <- clValid(legprof_mat, 2:10,
                        clMethod = c("hierarchical", "kmeans", "model"),
                        validation = "internal")
```

```{r}
summary(internal_all)
```

```{r}
par(mfrow = c(2, 2))
plot(internal_all, legend = FALSE,
     type = "l",
     main = " ")
par(mfrow = c(1, 1))
```

In these plots, the black solid line represents hierarchical clustering, the dashed red line represents k-means, and the dotted green line represents Gaussian mixture models. On the connectivity front, a lower score indicates a good configuration of clusters, The opposite is true for the silhouette width and Dunn index, in those cases, higher values indicate good clustering. In each case for each model, it appears that 2 clusters provide the best fit.

### Question 9: Discussion

#### Part (a)

Perhaps the biggest overarching takeaway is that it's difficult to meaningfully cluster a dataset of 49 observations. For all clustering methods and all validation metrics, 2 clusters was the optimum split, suggesting that there are few insights to be gained by arranging the data more granularly than that. This suggests that the most important distinction to be drawn in the dataset is that between the "highly professional legislatures" (CA, MA, MI, NY, OH, PA, and potentially IL depending on the method) and all other state legislatures. 

#### Part (b)

The Gaussian mixture model performs most poorly for all cluster values on all validation metrics, so it's probably safe to say that approach is not optimal. Between the hierarchical clustering and k-means approaches, they perform roughly the same at most cluster values, and vritually identically at the optimal cluster value of 2. This optimal value of k = 2 holds for all configurations of models and metrics.

#### Part (c)

There could be a few reasons to select a sub-optimal partitioning method. Accepting only the "optimal" method precludes any insight we could gain into sub-clusters of the remaining "less professional" state legislatures outside of the "highly professional" ones. There might be insight to be gained by setting k > 2 to see how sub-clusters form, even if the validation metrics on the overall clustering are not as strong. In a more rigorous project, I would also be interested in dropping California from all analyses, as tested in Question 6, to see whether the strong cluster it formed with the other "professional" legislatures was merely a product of how much of a high outlier it was. Although the Gaussian mixture model performed the most poorly here, you might still choose to use it regardless of validation statistics in a setting where you have a strong theoretical prior a certain variable should be composed of multiple Gaussians.

